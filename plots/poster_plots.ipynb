{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>negativity</th>\n",
       "      <th>positivity</th>\n",
       "      <th>agreement</th>\n",
       "      <th>vulgarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sports</td>\n",
       "      <td>0.089352</td>\n",
       "      <td>0.140203</td>\n",
       "      <td>0.899411</td>\n",
       "      <td>0.084548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Video Games</td>\n",
       "      <td>0.079255</td>\n",
       "      <td>0.149531</td>\n",
       "      <td>0.856568</td>\n",
       "      <td>0.068149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Music</td>\n",
       "      <td>0.071611</td>\n",
       "      <td>0.159956</td>\n",
       "      <td>0.915300</td>\n",
       "      <td>0.104271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Politics</td>\n",
       "      <td>0.103010</td>\n",
       "      <td>0.112316</td>\n",
       "      <td>0.843408</td>\n",
       "      <td>0.129858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Group  negativity  positivity  agreement  vulgarity\n",
       "0       Sports    0.089352    0.140203   0.899411   0.084548\n",
       "1  Video Games    0.079255    0.149531   0.856568   0.068149\n",
       "2        Music    0.071611    0.159956   0.915300   0.104271\n",
       "3     Politics    0.103010    0.112316   0.843408   0.129858"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_metrics = pd.read_csv('../docs/assets/data/category_metrics.csv')\n",
    "category_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sports', 'Video Games', 'Music', 'Politics'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_metrics.Group.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valentin/anaconda3/envs/ada/lib/python3.6/site-packages/plotly/offline/offline.py:635: UserWarning:\n",
      "\n",
      "Your filename `category_negativity` didn't end with .html. Adding .html to the end of your file.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'file:///home/valentin/Documents/EPFL/Master/Semestre1/ADA/Reddit-opinions-polarization/plots/category_negativity.html'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = go.Layout(\n",
    "    title=\"Negativity of general topics\",\n",
    "    xaxis=dict(\n",
    "        tickfont=dict(\n",
    "            size=14,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Negativity',\n",
    "        titlefont=dict(\n",
    "            size=16,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            size=14,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        )\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=1.0,\n",
    "        bgcolor='rgba(255, 255, 255, 0)',\n",
    "        bordercolor='rgba(255, 255, 255, 0)'\n",
    "    )\n",
    ")\n",
    "\n",
    "negativity_data = [go.Bar(\n",
    "                x=category_metrics.Group.values,\n",
    "                y=category_metrics.negativity.values,\n",
    "                marker=dict(\n",
    "                    color=['rgba(204,204,204,1)', 'rgba(222,45,38,0.8)',\n",
    "                           'rgba(204,204,204,1)', 'rgba(204,204,204,1)']))]\n",
    "\n",
    "cat_neg_fig = go.Figure(data=negativity_data, layout=layout)\n",
    "\n",
    "plotly.offline.plot(cat_neg_fig, auto_open=False, filename='category_negativity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valentin/anaconda3/envs/ada/lib/python3.6/site-packages/plotly/offline/offline.py:635: UserWarning:\n",
      "\n",
      "Your filename `category_vulgarity` didn't end with .html. Adding .html to the end of your file.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'file:///home/valentin/Documents/EPFL/Master/Semestre1/ADA/Reddit-opinions-polarization/plots/category_vulgarity.html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = go.Layout(\n",
    "    title=\"Vulgarity of general topics\",\n",
    "    xaxis=dict(\n",
    "        tickfont=dict(\n",
    "            size=14,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Vulgarity',\n",
    "        titlefont=dict(\n",
    "            size=16,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            size=14,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        )\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=1.0,\n",
    "        bgcolor='rgba(255, 255, 255, 0)',\n",
    "        bordercolor='rgba(255, 255, 255, 0)'\n",
    "    )\n",
    ")\n",
    "\n",
    "vulgarity_data = [go.Bar(\n",
    "                x=category_metrics.Group.values,\n",
    "                y=category_metrics.vulgarity.values,\n",
    "                marker=dict(\n",
    "                    color=['rgba(204,204,204,1)', 'rgba(222,45,38,0.8)',\n",
    "                           'rgba(204,204,204,1)', 'rgba(204,204,204,1)']))]\n",
    "\n",
    "cat_vulg_fig = go.Figure(data=vulgarity_data, layout=layout)\n",
    "\n",
    "plotly.offline.plot(cat_vulg_fig, auto_open=False, filename='category_vulgarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>count_pos</th>\n",
       "      <th>count_neg</th>\n",
       "      <th>agreement_factor</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>vulg</th>\n",
       "      <th>count</th>\n",
       "      <th>neg_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>63378</td>\n",
       "      <td>4638</td>\n",
       "      <td>0.931810</td>\n",
       "      <td>0.119226</td>\n",
       "      <td>0.089602</td>\n",
       "      <td>0.790424</td>\n",
       "      <td>0.144155</td>\n",
       "      <td>68016</td>\n",
       "      <td>0.029624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>funny</td>\n",
       "      <td>21933</td>\n",
       "      <td>3868</td>\n",
       "      <td>0.850083</td>\n",
       "      <td>0.123265</td>\n",
       "      <td>0.088850</td>\n",
       "      <td>0.786654</td>\n",
       "      <td>0.119805</td>\n",
       "      <td>25801</td>\n",
       "      <td>0.034415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics</td>\n",
       "      <td>16991</td>\n",
       "      <td>4020</td>\n",
       "      <td>0.808672</td>\n",
       "      <td>0.114051</td>\n",
       "      <td>0.103525</td>\n",
       "      <td>0.782111</td>\n",
       "      <td>0.120485</td>\n",
       "      <td>21011</td>\n",
       "      <td>0.010526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pics</td>\n",
       "      <td>17451</td>\n",
       "      <td>3407</td>\n",
       "      <td>0.836657</td>\n",
       "      <td>0.132045</td>\n",
       "      <td>0.085981</td>\n",
       "      <td>0.781025</td>\n",
       "      <td>0.106753</td>\n",
       "      <td>20858</td>\n",
       "      <td>0.046064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nfl</td>\n",
       "      <td>14686</td>\n",
       "      <td>1466</td>\n",
       "      <td>0.909237</td>\n",
       "      <td>0.139407</td>\n",
       "      <td>0.096617</td>\n",
       "      <td>0.762533</td>\n",
       "      <td>0.092520</td>\n",
       "      <td>16152</td>\n",
       "      <td>0.042790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>11642</td>\n",
       "      <td>2908</td>\n",
       "      <td>0.800137</td>\n",
       "      <td>0.156009</td>\n",
       "      <td>0.092606</td>\n",
       "      <td>0.750250</td>\n",
       "      <td>0.080653</td>\n",
       "      <td>14550</td>\n",
       "      <td>0.063403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nba</td>\n",
       "      <td>12699</td>\n",
       "      <td>1750</td>\n",
       "      <td>0.878884</td>\n",
       "      <td>0.138332</td>\n",
       "      <td>0.092943</td>\n",
       "      <td>0.767919</td>\n",
       "      <td>0.087987</td>\n",
       "      <td>14449</td>\n",
       "      <td>0.045389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>worldnews</td>\n",
       "      <td>11101</td>\n",
       "      <td>3301</td>\n",
       "      <td>0.770796</td>\n",
       "      <td>0.108674</td>\n",
       "      <td>0.108632</td>\n",
       "      <td>0.782373</td>\n",
       "      <td>0.132544</td>\n",
       "      <td>14402</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gaming</td>\n",
       "      <td>12104</td>\n",
       "      <td>2107</td>\n",
       "      <td>0.851735</td>\n",
       "      <td>0.137304</td>\n",
       "      <td>0.087848</td>\n",
       "      <td>0.773803</td>\n",
       "      <td>0.105931</td>\n",
       "      <td>14211</td>\n",
       "      <td>0.049456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WTF</td>\n",
       "      <td>12080</td>\n",
       "      <td>1960</td>\n",
       "      <td>0.860399</td>\n",
       "      <td>0.113473</td>\n",
       "      <td>0.105821</td>\n",
       "      <td>0.779859</td>\n",
       "      <td>0.149445</td>\n",
       "      <td>14040</td>\n",
       "      <td>0.007652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>videos</td>\n",
       "      <td>11224</td>\n",
       "      <td>2401</td>\n",
       "      <td>0.823780</td>\n",
       "      <td>0.129338</td>\n",
       "      <td>0.097098</td>\n",
       "      <td>0.772843</td>\n",
       "      <td>0.141633</td>\n",
       "      <td>13625</td>\n",
       "      <td>0.032240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>11335</td>\n",
       "      <td>2041</td>\n",
       "      <td>0.847413</td>\n",
       "      <td>0.118543</td>\n",
       "      <td>0.097175</td>\n",
       "      <td>0.783414</td>\n",
       "      <td>0.162529</td>\n",
       "      <td>13376</td>\n",
       "      <td>0.021368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>soccer</td>\n",
       "      <td>11381</td>\n",
       "      <td>1863</td>\n",
       "      <td>0.859333</td>\n",
       "      <td>0.144376</td>\n",
       "      <td>0.089149</td>\n",
       "      <td>0.765523</td>\n",
       "      <td>0.085555</td>\n",
       "      <td>13244</td>\n",
       "      <td>0.055227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>todayilearned</td>\n",
       "      <td>10642</td>\n",
       "      <td>1855</td>\n",
       "      <td>0.851564</td>\n",
       "      <td>0.115046</td>\n",
       "      <td>0.092240</td>\n",
       "      <td>0.792158</td>\n",
       "      <td>0.121992</td>\n",
       "      <td>12497</td>\n",
       "      <td>0.022806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>news</td>\n",
       "      <td>7959</td>\n",
       "      <td>2287</td>\n",
       "      <td>0.776791</td>\n",
       "      <td>0.102884</td>\n",
       "      <td>0.116782</td>\n",
       "      <td>0.780287</td>\n",
       "      <td>0.157253</td>\n",
       "      <td>10246</td>\n",
       "      <td>-0.013898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The_Donald</td>\n",
       "      <td>8723</td>\n",
       "      <td>188</td>\n",
       "      <td>0.978902</td>\n",
       "      <td>0.125407</td>\n",
       "      <td>0.099455</td>\n",
       "      <td>0.773762</td>\n",
       "      <td>0.122812</td>\n",
       "      <td>8911</td>\n",
       "      <td>0.025952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SquaredCircle</td>\n",
       "      <td>7751</td>\n",
       "      <td>808</td>\n",
       "      <td>0.905596</td>\n",
       "      <td>0.132494</td>\n",
       "      <td>0.086763</td>\n",
       "      <td>0.780387</td>\n",
       "      <td>0.101912</td>\n",
       "      <td>8559</td>\n",
       "      <td>0.045731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>movies</td>\n",
       "      <td>7274</td>\n",
       "      <td>905</td>\n",
       "      <td>0.889351</td>\n",
       "      <td>0.139762</td>\n",
       "      <td>0.087840</td>\n",
       "      <td>0.771698</td>\n",
       "      <td>0.103031</td>\n",
       "      <td>8179</td>\n",
       "      <td>0.051922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hockey</td>\n",
       "      <td>7581</td>\n",
       "      <td>571</td>\n",
       "      <td>0.929956</td>\n",
       "      <td>0.143589</td>\n",
       "      <td>0.095872</td>\n",
       "      <td>0.759544</td>\n",
       "      <td>0.084870</td>\n",
       "      <td>8152</td>\n",
       "      <td>0.047717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>relationships</td>\n",
       "      <td>6782</td>\n",
       "      <td>958</td>\n",
       "      <td>0.876227</td>\n",
       "      <td>0.129729</td>\n",
       "      <td>0.097524</td>\n",
       "      <td>0.772266</td>\n",
       "      <td>0.265359</td>\n",
       "      <td>7740</td>\n",
       "      <td>0.032204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CFB</td>\n",
       "      <td>7070</td>\n",
       "      <td>485</td>\n",
       "      <td>0.935804</td>\n",
       "      <td>0.139911</td>\n",
       "      <td>0.094557</td>\n",
       "      <td>0.764734</td>\n",
       "      <td>0.075720</td>\n",
       "      <td>7555</td>\n",
       "      <td>0.045353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>IAmA</td>\n",
       "      <td>6285</td>\n",
       "      <td>870</td>\n",
       "      <td>0.878407</td>\n",
       "      <td>0.140676</td>\n",
       "      <td>0.073168</td>\n",
       "      <td>0.785693</td>\n",
       "      <td>0.114306</td>\n",
       "      <td>7155</td>\n",
       "      <td>0.067508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DotA2</td>\n",
       "      <td>5370</td>\n",
       "      <td>1312</td>\n",
       "      <td>0.803652</td>\n",
       "      <td>0.145070</td>\n",
       "      <td>0.092268</td>\n",
       "      <td>0.760480</td>\n",
       "      <td>0.104957</td>\n",
       "      <td>6682</td>\n",
       "      <td>0.052802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gifs</td>\n",
       "      <td>4800</td>\n",
       "      <td>708</td>\n",
       "      <td>0.871460</td>\n",
       "      <td>0.123766</td>\n",
       "      <td>0.084409</td>\n",
       "      <td>0.790549</td>\n",
       "      <td>0.096758</td>\n",
       "      <td>5508</td>\n",
       "      <td>0.039357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>atheism</td>\n",
       "      <td>4546</td>\n",
       "      <td>773</td>\n",
       "      <td>0.854672</td>\n",
       "      <td>0.126700</td>\n",
       "      <td>0.096953</td>\n",
       "      <td>0.776234</td>\n",
       "      <td>0.135619</td>\n",
       "      <td>5319</td>\n",
       "      <td>0.029747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Games</td>\n",
       "      <td>4381</td>\n",
       "      <td>705</td>\n",
       "      <td>0.861384</td>\n",
       "      <td>0.130210</td>\n",
       "      <td>0.079859</td>\n",
       "      <td>0.789820</td>\n",
       "      <td>0.098970</td>\n",
       "      <td>5086</td>\n",
       "      <td>0.050351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>trees</td>\n",
       "      <td>4633</td>\n",
       "      <td>323</td>\n",
       "      <td>0.934826</td>\n",
       "      <td>0.163091</td>\n",
       "      <td>0.072425</td>\n",
       "      <td>0.763822</td>\n",
       "      <td>0.113080</td>\n",
       "      <td>4956</td>\n",
       "      <td>0.090666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>hiphopheads</td>\n",
       "      <td>4303</td>\n",
       "      <td>379</td>\n",
       "      <td>0.919052</td>\n",
       "      <td>0.146203</td>\n",
       "      <td>0.091158</td>\n",
       "      <td>0.761544</td>\n",
       "      <td>0.190594</td>\n",
       "      <td>4682</td>\n",
       "      <td>0.055045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MMA</td>\n",
       "      <td>3857</td>\n",
       "      <td>644</td>\n",
       "      <td>0.856921</td>\n",
       "      <td>0.135677</td>\n",
       "      <td>0.108582</td>\n",
       "      <td>0.755619</td>\n",
       "      <td>0.122555</td>\n",
       "      <td>4501</td>\n",
       "      <td>0.027095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>technology</td>\n",
       "      <td>3774</td>\n",
       "      <td>613</td>\n",
       "      <td>0.860269</td>\n",
       "      <td>0.106285</td>\n",
       "      <td>0.082931</td>\n",
       "      <td>0.810603</td>\n",
       "      <td>0.109813</td>\n",
       "      <td>4387</td>\n",
       "      <td>0.023354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>anime</td>\n",
       "      <td>4085</td>\n",
       "      <td>225</td>\n",
       "      <td>0.947796</td>\n",
       "      <td>0.148101</td>\n",
       "      <td>0.075224</td>\n",
       "      <td>0.776240</td>\n",
       "      <td>0.094145</td>\n",
       "      <td>4310</td>\n",
       "      <td>0.072877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>aww</td>\n",
       "      <td>3595</td>\n",
       "      <td>605</td>\n",
       "      <td>0.855952</td>\n",
       "      <td>0.167386</td>\n",
       "      <td>0.071816</td>\n",
       "      <td>0.760204</td>\n",
       "      <td>0.059833</td>\n",
       "      <td>4200</td>\n",
       "      <td>0.095570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GlobalOffensive</td>\n",
       "      <td>3412</td>\n",
       "      <td>771</td>\n",
       "      <td>0.815683</td>\n",
       "      <td>0.151364</td>\n",
       "      <td>0.086550</td>\n",
       "      <td>0.760668</td>\n",
       "      <td>0.087193</td>\n",
       "      <td>4183</td>\n",
       "      <td>0.064814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>baseball</td>\n",
       "      <td>3799</td>\n",
       "      <td>339</td>\n",
       "      <td>0.918076</td>\n",
       "      <td>0.135555</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>0.778270</td>\n",
       "      <td>0.077064</td>\n",
       "      <td>4138</td>\n",
       "      <td>0.050442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SubredditDrama</td>\n",
       "      <td>3423</td>\n",
       "      <td>570</td>\n",
       "      <td>0.857250</td>\n",
       "      <td>0.117516</td>\n",
       "      <td>0.098684</td>\n",
       "      <td>0.782425</td>\n",
       "      <td>0.221790</td>\n",
       "      <td>3993</td>\n",
       "      <td>0.018832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>3611</td>\n",
       "      <td>382</td>\n",
       "      <td>0.904333</td>\n",
       "      <td>0.155566</td>\n",
       "      <td>0.062792</td>\n",
       "      <td>0.779249</td>\n",
       "      <td>0.064388</td>\n",
       "      <td>3993</td>\n",
       "      <td>0.092774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>TumblrInAction</td>\n",
       "      <td>3825</td>\n",
       "      <td>135</td>\n",
       "      <td>0.965909</td>\n",
       "      <td>0.112789</td>\n",
       "      <td>0.106050</td>\n",
       "      <td>0.780824</td>\n",
       "      <td>0.225641</td>\n",
       "      <td>3960</td>\n",
       "      <td>0.006739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>reddit.com</td>\n",
       "      <td>3260</td>\n",
       "      <td>619</td>\n",
       "      <td>0.840423</td>\n",
       "      <td>0.127038</td>\n",
       "      <td>0.092911</td>\n",
       "      <td>0.779291</td>\n",
       "      <td>0.139343</td>\n",
       "      <td>3879</td>\n",
       "      <td>0.034128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>TwoXChromosomes</td>\n",
       "      <td>2979</td>\n",
       "      <td>629</td>\n",
       "      <td>0.825665</td>\n",
       "      <td>0.145978</td>\n",
       "      <td>0.091565</td>\n",
       "      <td>0.762140</td>\n",
       "      <td>0.288637</td>\n",
       "      <td>3608</td>\n",
       "      <td>0.054412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>hearthstone</td>\n",
       "      <td>2860</td>\n",
       "      <td>514</td>\n",
       "      <td>0.847659</td>\n",
       "      <td>0.153370</td>\n",
       "      <td>0.080178</td>\n",
       "      <td>0.764996</td>\n",
       "      <td>0.047677</td>\n",
       "      <td>3374</td>\n",
       "      <td>0.073192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>fffffffuuuuuuuuuuuu</td>\n",
       "      <td>2915</td>\n",
       "      <td>383</td>\n",
       "      <td>0.883869</td>\n",
       "      <td>0.128211</td>\n",
       "      <td>0.098332</td>\n",
       "      <td>0.772809</td>\n",
       "      <td>0.133022</td>\n",
       "      <td>3298</td>\n",
       "      <td>0.029879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>starcraft</td>\n",
       "      <td>2419</td>\n",
       "      <td>813</td>\n",
       "      <td>0.748453</td>\n",
       "      <td>0.151295</td>\n",
       "      <td>0.087848</td>\n",
       "      <td>0.759474</td>\n",
       "      <td>0.088089</td>\n",
       "      <td>3232</td>\n",
       "      <td>0.063447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>europe</td>\n",
       "      <td>2757</td>\n",
       "      <td>371</td>\n",
       "      <td>0.881394</td>\n",
       "      <td>0.111861</td>\n",
       "      <td>0.090586</td>\n",
       "      <td>0.797355</td>\n",
       "      <td>0.088194</td>\n",
       "      <td>3128</td>\n",
       "      <td>0.021274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>asoiaf</td>\n",
       "      <td>3016</td>\n",
       "      <td>105</td>\n",
       "      <td>0.966357</td>\n",
       "      <td>0.112603</td>\n",
       "      <td>0.086227</td>\n",
       "      <td>0.800980</td>\n",
       "      <td>0.107435</td>\n",
       "      <td>3121</td>\n",
       "      <td>0.026375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>pokemon</td>\n",
       "      <td>2782</td>\n",
       "      <td>261</td>\n",
       "      <td>0.914229</td>\n",
       "      <td>0.149296</td>\n",
       "      <td>0.070268</td>\n",
       "      <td>0.779505</td>\n",
       "      <td>0.043987</td>\n",
       "      <td>3043</td>\n",
       "      <td>0.079028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>cringepics</td>\n",
       "      <td>2637</td>\n",
       "      <td>404</td>\n",
       "      <td>0.867149</td>\n",
       "      <td>0.125073</td>\n",
       "      <td>0.095809</td>\n",
       "      <td>0.778087</td>\n",
       "      <td>0.141929</td>\n",
       "      <td>3041</td>\n",
       "      <td>0.029264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>magicTCG</td>\n",
       "      <td>2692</td>\n",
       "      <td>340</td>\n",
       "      <td>0.887863</td>\n",
       "      <td>0.136946</td>\n",
       "      <td>0.069149</td>\n",
       "      <td>0.793767</td>\n",
       "      <td>0.035239</td>\n",
       "      <td>3032</td>\n",
       "      <td>0.067797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Android</td>\n",
       "      <td>2664</td>\n",
       "      <td>357</td>\n",
       "      <td>0.881827</td>\n",
       "      <td>0.128114</td>\n",
       "      <td>0.062832</td>\n",
       "      <td>0.808536</td>\n",
       "      <td>0.057965</td>\n",
       "      <td>3021</td>\n",
       "      <td>0.065282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>AskMen</td>\n",
       "      <td>2759</td>\n",
       "      <td>228</td>\n",
       "      <td>0.923669</td>\n",
       "      <td>0.143615</td>\n",
       "      <td>0.084468</td>\n",
       "      <td>0.771472</td>\n",
       "      <td>0.277080</td>\n",
       "      <td>2987</td>\n",
       "      <td>0.059147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>smashbros</td>\n",
       "      <td>2624</td>\n",
       "      <td>280</td>\n",
       "      <td>0.903581</td>\n",
       "      <td>0.147641</td>\n",
       "      <td>0.078191</td>\n",
       "      <td>0.772931</td>\n",
       "      <td>0.048544</td>\n",
       "      <td>2904</td>\n",
       "      <td>0.069450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              subreddit  count_pos  count_neg  agreement_factor       pos  \\\n",
       "0             AskReddit      63378       4638          0.931810  0.119226   \n",
       "1                 funny      21933       3868          0.850083  0.123265   \n",
       "2              politics      16991       4020          0.808672  0.114051   \n",
       "3                  pics      17451       3407          0.836657  0.132045   \n",
       "4                   nfl      14686       1466          0.909237  0.139407   \n",
       "5       leagueoflegends      11642       2908          0.800137  0.156009   \n",
       "6                   nba      12699       1750          0.878884  0.138332   \n",
       "7             worldnews      11101       3301          0.770796  0.108674   \n",
       "8                gaming      12104       2107          0.851735  0.137304   \n",
       "9                   WTF      12080       1960          0.860399  0.113473   \n",
       "10               videos      11224       2401          0.823780  0.129338   \n",
       "11        AdviceAnimals      11335       2041          0.847413  0.118543   \n",
       "12               soccer      11381       1863          0.859333  0.144376   \n",
       "13        todayilearned      10642       1855          0.851564  0.115046   \n",
       "14                 news       7959       2287          0.776791  0.102884   \n",
       "15           The_Donald       8723        188          0.978902  0.125407   \n",
       "16        SquaredCircle       7751        808          0.905596  0.132494   \n",
       "17               movies       7274        905          0.889351  0.139762   \n",
       "18               hockey       7581        571          0.929956  0.143589   \n",
       "19        relationships       6782        958          0.876227  0.129729   \n",
       "20                  CFB       7070        485          0.935804  0.139911   \n",
       "21                 IAmA       6285        870          0.878407  0.140676   \n",
       "22                DotA2       5370       1312          0.803652  0.145070   \n",
       "23                 gifs       4800        708          0.871460  0.123766   \n",
       "24              atheism       4546        773          0.854672  0.126700   \n",
       "25                Games       4381        705          0.861384  0.130210   \n",
       "26                trees       4633        323          0.934826  0.163091   \n",
       "27          hiphopheads       4303        379          0.919052  0.146203   \n",
       "28                  MMA       3857        644          0.856921  0.135677   \n",
       "29           technology       3774        613          0.860269  0.106285   \n",
       "30                anime       4085        225          0.947796  0.148101   \n",
       "31                  aww       3595        605          0.855952  0.167386   \n",
       "32      GlobalOffensive       3412        771          0.815683  0.151364   \n",
       "33             baseball       3799        339          0.918076  0.135555   \n",
       "34       SubredditDrama       3423        570          0.857250  0.117516   \n",
       "35         pcmasterrace       3611        382          0.904333  0.155566   \n",
       "36       TumblrInAction       3825        135          0.965909  0.112789   \n",
       "37           reddit.com       3260        619          0.840423  0.127038   \n",
       "38      TwoXChromosomes       2979        629          0.825665  0.145978   \n",
       "39          hearthstone       2860        514          0.847659  0.153370   \n",
       "40  fffffffuuuuuuuuuuuu       2915        383          0.883869  0.128211   \n",
       "41            starcraft       2419        813          0.748453  0.151295   \n",
       "42               europe       2757        371          0.881394  0.111861   \n",
       "43               asoiaf       3016        105          0.966357  0.112603   \n",
       "44              pokemon       2782        261          0.914229  0.149296   \n",
       "45           cringepics       2637        404          0.867149  0.125073   \n",
       "46             magicTCG       2692        340          0.887863  0.136946   \n",
       "47              Android       2664        357          0.881827  0.128114   \n",
       "48               AskMen       2759        228          0.923669  0.143615   \n",
       "49            smashbros       2624        280          0.903581  0.147641   \n",
       "\n",
       "         neg       neu      vulg  count   neg_pos  \n",
       "0   0.089602  0.790424  0.144155  68016  0.029624  \n",
       "1   0.088850  0.786654  0.119805  25801  0.034415  \n",
       "2   0.103525  0.782111  0.120485  21011  0.010526  \n",
       "3   0.085981  0.781025  0.106753  20858  0.046064  \n",
       "4   0.096617  0.762533  0.092520  16152  0.042790  \n",
       "5   0.092606  0.750250  0.080653  14550  0.063403  \n",
       "6   0.092943  0.767919  0.087987  14449  0.045389  \n",
       "7   0.108632  0.782373  0.132544  14402  0.000042  \n",
       "8   0.087848  0.773803  0.105931  14211  0.049456  \n",
       "9   0.105821  0.779859  0.149445  14040  0.007652  \n",
       "10  0.097098  0.772843  0.141633  13625  0.032240  \n",
       "11  0.097175  0.783414  0.162529  13376  0.021368  \n",
       "12  0.089149  0.765523  0.085555  13244  0.055227  \n",
       "13  0.092240  0.792158  0.121992  12497  0.022806  \n",
       "14  0.116782  0.780287  0.157253  10246 -0.013898  \n",
       "15  0.099455  0.773762  0.122812   8911  0.025952  \n",
       "16  0.086763  0.780387  0.101912   8559  0.045731  \n",
       "17  0.087840  0.771698  0.103031   8179  0.051922  \n",
       "18  0.095872  0.759544  0.084870   8152  0.047717  \n",
       "19  0.097524  0.772266  0.265359   7740  0.032204  \n",
       "20  0.094557  0.764734  0.075720   7555  0.045353  \n",
       "21  0.073168  0.785693  0.114306   7155  0.067508  \n",
       "22  0.092268  0.760480  0.104957   6682  0.052802  \n",
       "23  0.084409  0.790549  0.096758   5508  0.039357  \n",
       "24  0.096953  0.776234  0.135619   5319  0.029747  \n",
       "25  0.079859  0.789820  0.098970   5086  0.050351  \n",
       "26  0.072425  0.763822  0.113080   4956  0.090666  \n",
       "27  0.091158  0.761544  0.190594   4682  0.055045  \n",
       "28  0.108582  0.755619  0.122555   4501  0.027095  \n",
       "29  0.082931  0.810603  0.109813   4387  0.023354  \n",
       "30  0.075224  0.776240  0.094145   4310  0.072877  \n",
       "31  0.071816  0.760204  0.059833   4200  0.095570  \n",
       "32  0.086550  0.760668  0.087193   4183  0.064814  \n",
       "33  0.085113  0.778270  0.077064   4138  0.050442  \n",
       "34  0.098684  0.782425  0.221790   3993  0.018832  \n",
       "35  0.062792  0.779249  0.064388   3993  0.092774  \n",
       "36  0.106050  0.780824  0.225641   3960  0.006739  \n",
       "37  0.092911  0.779291  0.139343   3879  0.034128  \n",
       "38  0.091565  0.762140  0.288637   3608  0.054412  \n",
       "39  0.080178  0.764996  0.047677   3374  0.073192  \n",
       "40  0.098332  0.772809  0.133022   3298  0.029879  \n",
       "41  0.087848  0.759474  0.088089   3232  0.063447  \n",
       "42  0.090586  0.797355  0.088194   3128  0.021274  \n",
       "43  0.086227  0.800980  0.107435   3121  0.026375  \n",
       "44  0.070268  0.779505  0.043987   3043  0.079028  \n",
       "45  0.095809  0.778087  0.141929   3041  0.029264  \n",
       "46  0.069149  0.793767  0.035239   3032  0.067797  \n",
       "47  0.062832  0.808536  0.057965   3021  0.065282  \n",
       "48  0.084468  0.771472  0.277080   2987  0.059147  \n",
       "49  0.078191  0.772931  0.048544   2904  0.069450  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddits_metrics = pd.read_csv('../docs/assets/data/subreddit_metrics.csv')\n",
    "subreddits_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AskReddit',\n",
       " 'funny',\n",
       " 'politics',\n",
       " 'pics',\n",
       " 'nfl',\n",
       " 'leagueoflegends',\n",
       " 'nba',\n",
       " 'worldnews',\n",
       " 'news',\n",
       " 'The_Donald',\n",
       " 'trees',\n",
       " 'technology',\n",
       " 'anime',\n",
       " 'aww',\n",
       " 'TumblrInAction',\n",
       " 'starcraft',\n",
       " 'europe',\n",
       " 'pokemon',\n",
       " 'hearstone, GlobalOffensive',\n",
       " 'DotA2',\n",
       " 'soccer',\n",
       " 'gaming',\n",
       " 'Games']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddits_metrics_names = pd.read_csv('../docs/assets/data/subreddit_metrics_names.csv')\n",
    "names = subreddits_metrics_names['subreddit'].values\n",
    "names = list(names)\n",
    "additional = ['hearstone, GlobalOffensive', 'DotA2', 'soccer', 'gaming', 'Games']\n",
    "names = names + additional\n",
    "names.remove('MMA')\n",
    "names.remove('TwoXChromosomes')\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_video_games_names = ['leagueoflegends', 'gaming', 'DotA2', 'Games', 'GlobalOffensive', 'hearthstone', 'starcraft']\n",
    "sub_politics_names = ['politics', 'worldnews', 'news']\n",
    "sub_wholesome_names = ['aww', 'trees']\n",
    "sub_donald_names = ['The_Donald']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_filtered(filter_list):\n",
    "    return subreddits_metrics['subreddit'].apply(lambda x: x in filter_list)\n",
    "\n",
    "def inverse_sub_filtered():\n",
    "    return subreddits_metrics['subreddit'].apply(lambda x: x not in sub_video_games_names and x not in sub_politics_names and x not in sub_wholesome_names and x not in sub_donald_names and x not in ['asoiaf', 'fffffffuuuuuuuuuuuu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_games_filter = sub_filtered(sub_video_games_names)\n",
    "politics_filter = sub_filtered(sub_politics_names)\n",
    "wholesome_filter = sub_filtered(sub_wholesome_names)\n",
    "donald_filter = sub_filtered(sub_donald_names)\n",
    "others_filter = inverse_sub_filtered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_video_games = subreddits_metrics.loc[video_games_filter]\n",
    "sub_politics = subreddits_metrics.loc[politics_filter]\n",
    "sub_wholesome = subreddits_metrics.loc[wholesome_filter]\n",
    "sub_donald = subreddits_metrics.loc[donald_filter]\n",
    "sub_others = subreddits_metrics.loc[others_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scatter_trace(subreddit, sub_name, marker_symbol, marker_color, marker_size):\n",
    "    trace = go.Scatter(\n",
    "                x=subreddit.agreement_factor,\n",
    "                y=subreddit.pos,\n",
    "                name=sub_name,\n",
    "                marker=dict(\n",
    "                    color=marker_color,\n",
    "                    symbol=marker_symbol,\n",
    "                    size=marker_size\n",
    "                ),\n",
    "                mode='markers+text',\n",
    "                text=subreddit['subreddit'].values,\n",
    "                textposition='top center',\n",
    "                textfont=dict(size=10),\n",
    "                showlegend=False)\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valentin/anaconda3/envs/ada/lib/python3.6/site-packages/plotly/offline/offline.py:635: UserWarning:\n",
      "\n",
      "Your filename `category_agree_vs_pos_vulg` didn't end with .html. Adding .html to the end of your file.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'file:///home/valentin/Documents/EPFL/Master/Semestre1/ADA/Reddit-opinions-polarization/plots/category_agree_vs_pos_vulg.html'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = go.Layout(\n",
    "    title='Communities: Agreement and Positivity',\n",
    "    xaxis=dict(\n",
    "        titlefont=dict(\n",
    "            size=12,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        ),\n",
    "        range=[0.73, 1]\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        titlefont=dict(\n",
    "            size=12,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        )\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=-0.1,\n",
    "        y=-0.175\n",
    "    )\n",
    ")\n",
    "\n",
    "agree_pos_vg_trace = create_scatter_trace(sub_video_games, 'Video games', 2, 'rgb(146, 197, 122)', 8)\n",
    "agree_pos_politics_trace = create_scatter_trace(sub_politics, 'Politics', 1, 'rgb(103, 75, 169)', 8)\n",
    "agree_pos_wholesome_trace = create_scatter_trace(sub_wholesome, 'Wholesome', 17, 'rgb(248, 179, 101)', 10)\n",
    "agree_pos_donald_trace = create_scatter_trace(sub_donald, 'The_Donald', 4, 'rgb(226, 101, 99)', 8)\n",
    "#agree_pos_others_trace = create_scatter_trace(sub_others, 'Others', 28, 'rgb(168, 168, 168)')\n",
    "\n",
    "sub_others_names = sub_others['subreddit'].apply(lambda x: ' ' if x not in names else x).values\n",
    "agree_pos_others_trace = go.Scatter(\n",
    "                            x=sub_others.agreement_factor,\n",
    "                            y=sub_others.pos,\n",
    "                            name='Other communities',\n",
    "                            marker=dict(\n",
    "                                color='rgb(168, 168, 168)',\n",
    "                                symbol=28,\n",
    "                                size=6\n",
    "                            ),\n",
    "                            mode='markers+text',\n",
    "                            text=sub_others_names,\n",
    "                            textposition='top center',\n",
    "                            textfont=dict(\n",
    "                                size=10))\n",
    "\n",
    "agree_pos_data = [agree_pos_vg_trace, agree_pos_politics_trace, agree_pos_wholesome_trace, agree_pos_donald_trace, agree_pos_others_trace]\n",
    "\n",
    "scatter_fig = go.Figure(data=agree_pos_data, layout=layout)\n",
    "\n",
    "plotly.offline.plot(scatter_fig, auto_open=False, filename='category_agree_vs_pos_vulg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD SCATTER PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.035238504512247526, 0.2886367268659102)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vulgarity_min = subreddits_metrics['vulg'].min()\n",
    "vulgarity_max = subreddits_metrics['vulg'].max()\n",
    "vulgarity_space = np.linspace(vulgarity_min, vulgarity_max, 4)\n",
    "vulgarity_colors = ['rgb(3, 196, 42)', 'rgb(255, 158, 12)', 'rgb(178, 10, 10)']\n",
    "vulgarity_min, vulgarity_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valentin/anaconda3/envs/ada/lib/python3.6/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>count_pos</th>\n",
       "      <th>count_neg</th>\n",
       "      <th>agreement_factor</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>vulg</th>\n",
       "      <th>count</th>\n",
       "      <th>neg_pos</th>\n",
       "      <th>vulg_rgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>63378</td>\n",
       "      <td>4638</td>\n",
       "      <td>0.931810</td>\n",
       "      <td>0.119226</td>\n",
       "      <td>0.089602</td>\n",
       "      <td>0.790424</td>\n",
       "      <td>0.144155</td>\n",
       "      <td>68016</td>\n",
       "      <td>0.029624</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>funny</td>\n",
       "      <td>21933</td>\n",
       "      <td>3868</td>\n",
       "      <td>0.850083</td>\n",
       "      <td>0.123265</td>\n",
       "      <td>0.088850</td>\n",
       "      <td>0.786654</td>\n",
       "      <td>0.119805</td>\n",
       "      <td>25801</td>\n",
       "      <td>0.034415</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics</td>\n",
       "      <td>16991</td>\n",
       "      <td>4020</td>\n",
       "      <td>0.808672</td>\n",
       "      <td>0.114051</td>\n",
       "      <td>0.103525</td>\n",
       "      <td>0.782111</td>\n",
       "      <td>0.120485</td>\n",
       "      <td>21011</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pics</td>\n",
       "      <td>17451</td>\n",
       "      <td>3407</td>\n",
       "      <td>0.836657</td>\n",
       "      <td>0.132045</td>\n",
       "      <td>0.085981</td>\n",
       "      <td>0.781025</td>\n",
       "      <td>0.106753</td>\n",
       "      <td>20858</td>\n",
       "      <td>0.046064</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nfl</td>\n",
       "      <td>14686</td>\n",
       "      <td>1466</td>\n",
       "      <td>0.909237</td>\n",
       "      <td>0.139407</td>\n",
       "      <td>0.096617</td>\n",
       "      <td>0.762533</td>\n",
       "      <td>0.092520</td>\n",
       "      <td>16152</td>\n",
       "      <td>0.042790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit  count_pos  count_neg  agreement_factor       pos       neg  \\\n",
       "0  AskReddit      63378       4638          0.931810  0.119226  0.089602   \n",
       "1      funny      21933       3868          0.850083  0.123265  0.088850   \n",
       "2   politics      16991       4020          0.808672  0.114051  0.103525   \n",
       "3       pics      17451       3407          0.836657  0.132045  0.085981   \n",
       "4        nfl      14686       1466          0.909237  0.139407  0.096617   \n",
       "\n",
       "        neu      vulg  count   neg_pos  vulg_rgb  \n",
       "0  0.790424  0.144155  68016  0.029624         1  \n",
       "1  0.786654  0.119805  25801  0.034415         1  \n",
       "2  0.782111  0.120485  21011  0.010526         1  \n",
       "3  0.781025  0.106753  20858  0.046064         0  \n",
       "4  0.762533  0.092520  16152  0.042790         0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddits_metrics.loc[:, 'vulg_rgb'] = -1\n",
    "subreddits_metrics.loc[:, 'vulg_rgb'].loc[subreddits_metrics['vulg'] <= vulgarity_space[1]] = 0\n",
    "subreddits_metrics.loc[:, 'vulg_rgb'].loc[(subreddits_metrics['vulg'] > vulgarity_space[1]) & (subreddits_metrics['vulg'] <= vulgarity_space[2])] = 1\n",
    "subreddits_metrics.loc[:, 'vulg_rgb'].loc[subreddits_metrics['vulg'] > vulgarity_space[2]] = 2\n",
    "subreddits_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_low = subreddits_metrics[subreddits_metrics['vulg_rgb'] == 0]\n",
    "sub_medium = subreddits_metrics[subreddits_metrics['vulg_rgb'] == 1]\n",
    "sub_high = subreddits_metrics[subreddits_metrics['vulg_rgb'] == 2]\n",
    "\n",
    "sub_low_names = [' ' if x in ['asoiaf', 'fffffffuuuuuuuuuuuu'] else x for x in sub_low.subreddit.values]\n",
    "sub_medium_names = [' ' if x in ['asoiaf', 'fffffffuuuuuuuuuuuu'] else x for x in sub_medium.subreddit.values]\n",
    "sub_high_names = [' ' if x in ['asoiaf', 'fffffffuuuuuuuuuuuu'] else x for x in sub_high.subreddit.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valentin/anaconda3/envs/ada/lib/python3.6/site-packages/plotly/offline/offline.py:635: UserWarning:\n",
      "\n",
      "Your filename `blablablabla` didn't end with .html. Adding .html to the end of your file.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'file:///home/valentin/Documents/EPFL/Master/Semestre1/ADA/Reddit-opinions-polarization/plots/blablablabla.html'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = go.Layout(\n",
    "    title=\"Subreddits Agreement VS Positivity\",\n",
    "    xaxis=dict(\n",
    "        title='Agreement',\n",
    "        titlefont=dict(\n",
    "            size=16,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Positivity',\n",
    "        titlefont=dict(\n",
    "            size=16,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        )\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=-0.05,\n",
    "        font=dict(size=16),\n",
    "        bgcolor='rgba(255, 255, 255, 0)',\n",
    "        bordercolor='rgba(255, 255, 255, 0)',\n",
    "        orientation='h'\n",
    "    )\n",
    ")\n",
    "\n",
    "agree_pos_low_vulg_trace = go.Scatter(\n",
    "                x=sub_low.agreement_factor,\n",
    "                y=sub_low.pos,\n",
    "                name='Low vulgarity',\n",
    "                marker=dict(\n",
    "                    color=vulgarity_colors[0]\n",
    "                ),\n",
    "                mode='markers+text',\n",
    "                text=sub_low_names,\n",
    "                textposition='top center')\n",
    "\n",
    "agree_pos_medium_vulg_trace = go.Scatter(\n",
    "                x=sub_medium.agreement_factor,\n",
    "                y=sub_medium.pos,\n",
    "                name='Moderate vulgarity',\n",
    "                marker=dict(\n",
    "                    color=vulgarity_colors[1]\n",
    "                ),\n",
    "                mode='markers+text',\n",
    "                text=sub_medium_names,\n",
    "                textposition='top center')\n",
    "\n",
    "agree_pos_high_vulg_trace = go.Scatter(\n",
    "                x=sub_high.agreement_factor,\n",
    "                y=sub_high.pos,\n",
    "                name='High vulgarity',\n",
    "                marker=dict(\n",
    "                    color=vulgarity_colors[2]\n",
    "                ),\n",
    "                mode='markers+text',\n",
    "                text=sub_high_names,\n",
    "                textposition='top center')\n",
    "\n",
    "\n",
    "old_scatter_fig = go.Figure(data=[agree_pos_low_vulg_trace, agree_pos_medium_vulg_trace, agree_pos_high_vulg_trace], layout=layout)\n",
    "\n",
    "plotly.offline.plot(old_scatter_fig, auto_open=False, filename='blablablabla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created</th>\n",
       "      <th>daily_agreement_60d_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.886314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>0.886281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>0.886209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>0.886569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>0.886850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        created  daily_agreement_60d_avg\n",
       "729  2011-01-01                 0.886314\n",
       "730  2011-01-02                 0.886281\n",
       "731  2011-01-03                 0.886209\n",
       "732  2011-01-04                 0.886569\n",
       "733  2011-01-05                 0.886850"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_agree = pd.read_csv('../docs/assets/data/daily_agreement.csv')\n",
    "dates = pd.to_datetime(daily_agree.loc[:, 'created'])\n",
    "dates_filter = dates.apply(lambda x: x.year >= 2011)\n",
    "daily_agree = daily_agree.loc[dates_filter]\n",
    "daily_agree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creation_date</th>\n",
       "      <th>nltk_positivity_60d_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.135623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>0.135559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>0.135456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>0.135390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>0.135251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     creation_date  nltk_positivity_60d_avg\n",
       "1817    2011-01-01                 0.135623\n",
       "1818    2011-01-02                 0.135559\n",
       "1819    2011-01-03                 0.135456\n",
       "1820    2011-01-04                 0.135390\n",
       "1821    2011-01-05                 0.135251"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_pos = pd.read_csv('../docs/assets/data/neg_vs_pos_daily_avg.csv')\n",
    "dates = pd.to_datetime(daily_pos.loc[:, 'creation_date'])\n",
    "dates_filter = dates.apply(lambda x: x.year >= 2011)\n",
    "daily_pos = daily_pos.loc[dates_filter].loc[:, ['creation_date', 'nltk_positivity_60d_avg']]\n",
    "daily_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_full_name = '../data/nlp_bw_metrics_daily_full_0.01.parquet/'\n",
    "bw_sql_table_name = 'bw_metrics'\n",
    "bw_sql_query = (f\"\"\"\n",
    "SELECT\n",
    "    creation_date,\n",
    "    \n",
    "    AVG(msg_count) OVER (\n",
    "        ORDER BY creation_date\n",
    "        RANGE BETWEEN 30 PRECEDING AND 30 FOLLOWING\n",
    "    ) AS msg_count_60d_avg,\n",
    "\n",
    "    AVG(sum_nb_bw_matches) OVER (\n",
    "        ORDER BY creation_date\n",
    "        RANGE BETWEEN 30 PRECEDING AND 30 FOLLOWING\n",
    "    ) AS nb_bw_matches_60d_avg\n",
    "\n",
    "FROM {bw_sql_table_name}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spark_to_pandas(spark_metrics):\n",
    "    metrics_pd = spark_metrics.toPandas()\n",
    "    metrics_pd = metrics_pd.set_index('creation_date')\n",
    "    metrics_pd = metrics_pd.sort_index()\n",
    "    return metrics_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(filename, sql_query, sql_table_name):\n",
    "    spark_metrics = spark.read.load(filename)\n",
    "    spark_metrics.registerTempTable(sql_table_name)\n",
    "    avg_metrics = spark.sql(sql_query)\n",
    "\n",
    "    pd_metrics = spark_to_pandas(spark_metrics)\n",
    "    pd_metrics_avg = spark_to_pandas(avg_metrics)\n",
    "    pd_metrics_n = pd_metrics.div(pd_metrics['msg_count'], axis=0)\n",
    "    pd_metrics_avg_n = pd_metrics_avg.div(pd_metrics_avg['msg_count_60d_avg'], axis=0)\n",
    "    \n",
    "    return pd_metrics_n, pd_metrics_avg_n, pd_metrics, pd_metrics_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vulg_n, vulg_avg_n, vulg, vulg_avg = get_metrics(bw_full_name, bw_sql_query, bw_sql_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creation_date</th>\n",
       "      <th>nb_bw_matches_60d_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>0.122371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>0.122122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>0.122508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>0.122262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>0.122170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     creation_date  nb_bw_matches_60d_avg\n",
       "1817    2011-01-01               0.122371\n",
       "1818    2011-01-02               0.122122\n",
       "1819    2011-01-03               0.122508\n",
       "1820    2011-01-04               0.122262\n",
       "1821    2011-01-05               0.122170"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_vulg = vulg_avg_n.copy()\n",
    "daily_vulg = daily_vulg.reset_index().drop('msg_count_60d_avg', axis=1)\n",
    "dates = pd.to_datetime(daily_vulg.loc[:, 'creation_date'])\n",
    "dates_filter = dates.apply(lambda x: x.year >= 2011)\n",
    "daily_vulg = daily_vulg[dates_filter]\n",
    "daily_vulg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#daily_vulg = spark.read.load('../data/nlp_bw_metrics_daily_full_0.01.parquet/')\n",
    "#daily_vulg = daily_vulg.toPandas()\n",
    "#daily_vulg = daily_vulg.sort_values(by='creation_date')\n",
    "#dates = pd.to_datetime(daily_vulg.loc[:, 'creation_date'])\n",
    "#dates_filter = dates.apply(lambda x: x.year >= 2011)\n",
    "#daily_vulg = daily_vulg[dates_filter]\n",
    "#daily_vulg['vulgarity'] = daily_vulg['sum_nb_bw_matches'] / daily_vulg['msg_count']\n",
    "#daily_vulg = daily_vulg.loc[:, ['creation_date', 'vulgarity']]\n",
    "#daily_vulg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>avg_nb_sub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>4.678156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>4.487831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>4.459591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2011-04-01</td>\n",
       "      <td>4.418013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2011-05-01</td>\n",
       "      <td>4.484318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  avg_nb_sub\n",
       "24  2011-01-01    4.678156\n",
       "25  2011-02-01    4.487831\n",
       "26  2011-03-01    4.459591\n",
       "27  2011-04-01    4.418013\n",
       "28  2011-05-01    4.484318"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_contrib = pd.read_csv('../docs/assets/data/monthly_contributions.csv')\n",
    "daily_contrib = daily_contrib.loc[:, ['date', 'avg_nb_sub']]\n",
    "dates = pd.to_datetime(daily_contrib.loc[:, 'date'])\n",
    "dates_filter = dates.apply(lambda x: x.year >= 2011)\n",
    "daily_contrib = daily_contrib[dates_filter]\n",
    "daily_contrib.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(serie):\n",
    "    serie_range = serie.max() - serie.min()\n",
    "    return (serie - serie.min()) / serie_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_agree['daily_agreement_60d_avg_n'] = normalize(daily_agree['daily_agreement_60d_avg'])\n",
    "daily_pos['nltk_positivity_60d_avg_n'] = normalize(daily_pos['nltk_positivity_60d_avg'])\n",
    "daily_vulg['vulgarity_n'] = normalize(daily_vulg['nb_bw_matches_60d_avg'])\n",
    "daily_contrib['avg_nb_sub_n'] = normalize(daily_contrib['avg_nb_sub'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "agree_trace = go.Scatter(\n",
    "    x = daily_agree['created'].values,\n",
    "    y = daily_agree['daily_agreement_60d_avg'].values,\n",
    "    mode='lines',\n",
    "    name='Agreement',\n",
    "    line = dict(\n",
    "        shape='spline',\n",
    "        width=4,\n",
    "        color='rgb(61, 133, 198)'\n",
    "    )\n",
    ")\n",
    "\n",
    "agree_trace_n = go.Scatter(\n",
    "    x = daily_agree['created'].values,\n",
    "    y = daily_agree['daily_agreement_60d_avg_n'].values,\n",
    "    mode='lines',\n",
    "    name='Agreement'\n",
    ")\n",
    "\n",
    "pos_trace = go.Scatter(\n",
    "    x = daily_pos['creation_date'].values,\n",
    "    y = daily_pos['nltk_positivity_60d_avg'].values,\n",
    "    mode='lines',\n",
    "    name='Positivity',\n",
    "    line = dict(\n",
    "        shape='spline',\n",
    "        width=4,\n",
    "        color='rgb(61, 133, 198)'\n",
    "    )\n",
    ")\n",
    "\n",
    "pos_trace_n = go.Scatter(\n",
    "    x = daily_pos['creation_date'].values,\n",
    "    y = daily_pos['nltk_positivity_60d_avg_n'].values,\n",
    "    mode='lines',\n",
    "    name='Positivity'\n",
    ")\n",
    "\n",
    "vulg_trace = go.Scatter(\n",
    "    x = daily_vulg['creation_date'].values,\n",
    "    y = daily_vulg['nb_bw_matches_60d_avg'].values,\n",
    "    mode='lines',\n",
    "    name='Vulgarity',\n",
    "    line = dict(\n",
    "        shape='spline',\n",
    "        width=4,\n",
    "        color='rgb(61, 133, 198)'\n",
    "    )\n",
    ")\n",
    "\n",
    "vulg_trace_n = go.Scatter(\n",
    "    x = daily_vulg['creation_date'].values,\n",
    "    y = daily_vulg['vulgarity_n'].values,\n",
    "    mode='lines',\n",
    "    name='Vulgarity'\n",
    ")\n",
    "\n",
    "contrib_trace = go.Scatter(\n",
    "    x = daily_contrib['date'].values,\n",
    "    y = daily_contrib['avg_nb_sub'].values,\n",
    "    mode='lines',\n",
    "    name='Contributions',\n",
    "    line = dict(\n",
    "        shape='spline',\n",
    "        width=4,\n",
    "        color='rgb(204, 65, 37)'\n",
    "    )\n",
    ")\n",
    "\n",
    "contrib_trace_n = go.Scatter(\n",
    "    x = daily_contrib['date'].values,\n",
    "    y = daily_contrib['avg_nb_sub_n'].values,\n",
    "    mode='lines',\n",
    "    name='Contributions'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = go.Layout(\n",
    "    xaxis=dict(\n",
    "        title='Time',\n",
    "        titlefont=dict(\n",
    "            size=22,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            size=22\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Agreement',\n",
    "        titlefont=dict(\n",
    "            size=22,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            size=22\n",
    "        )\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=-0.05,\n",
    "        font=dict(size=16),\n",
    "        bgcolor='rgba(255, 255, 255, 0)',\n",
    "        bordercolor='rgba(255, 255, 255, 0)',\n",
    "        orientation='h'\n",
    "    )\n",
    ")\n",
    "agree_line_fig = go.Figure(data=[agree_trace], layout=layout)\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(\n",
    "        title='Time',\n",
    "        titlefont=dict(\n",
    "            size=22,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            size=22\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Positivity',\n",
    "        titlefont=dict(\n",
    "            size=22,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            size=22\n",
    "        ),\n",
    "        dtick=0.004\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=-0.05,\n",
    "        font=dict(size=16),\n",
    "        bgcolor='rgba(255, 255, 255, 0)',\n",
    "        bordercolor='rgba(255, 255, 255, 0)',\n",
    "        orientation='h'\n",
    "    )\n",
    ")\n",
    "pos_line_fig = go.Figure(data=[pos_trace], layout=layout)\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(\n",
    "        title='Time',\n",
    "        titlefont=dict(\n",
    "            size=22,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            size=22\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Vulgarity',\n",
    "        titlefont=dict(\n",
    "            size=22,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            size=22\n",
    "        ),\n",
    "        dtick=0.01\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=-0.05,\n",
    "        font=dict(size=16),\n",
    "        bgcolor='rgba(255, 255, 255, 0)',\n",
    "        bordercolor='rgba(255, 255, 255, 0)',\n",
    "        orientation='h'\n",
    "    )\n",
    ")\n",
    "vulg_line_fig = go.Figure(data=[vulg_trace], layout=layout)\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(\n",
    "        title='Time',\n",
    "        titlefont=dict(\n",
    "            size=22,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            size=22\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Contribution',\n",
    "        titlefont=dict(\n",
    "            size=22,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            size=22\n",
    "        )\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=-0.05,\n",
    "        font=dict(size=16),\n",
    "        bgcolor='rgba(255, 255, 255, 0)',\n",
    "        bordercolor='rgba(255, 255, 255, 0)',\n",
    "        orientation='h'\n",
    "    )\n",
    ")\n",
    "contrib_line_fig = go.Figure(data=[contrib_trace], layout=layout)\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"Sentiment over time\",\n",
    "    xaxis=dict(\n",
    "        title='Time',\n",
    "        titlefont=dict(\n",
    "            size=16,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Sentiments',\n",
    "        titlefont=dict(\n",
    "            size=16,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        )\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=-0.05,\n",
    "        font=dict(size=16),\n",
    "        bgcolor='rgba(255, 255, 255, 0)',\n",
    "        bordercolor='rgba(255, 255, 255, 0)',\n",
    "        orientation='h'\n",
    "    )\n",
    ")\n",
    "lines_fig = go.Figure(data=[agree_trace_n, pos_trace_n, vulg_trace_n, contrib_trace_n], layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valentin/anaconda3/envs/ada/lib/python3.6/site-packages/plotly/offline/offline.py:635: UserWarning:\n",
      "\n",
      "Your filename `agree_over_time` didn't end with .html. Adding .html to the end of your file.\n",
      "\n",
      "/home/valentin/anaconda3/envs/ada/lib/python3.6/site-packages/plotly/offline/offline.py:635: UserWarning:\n",
      "\n",
      "Your filename `pos_over_time` didn't end with .html. Adding .html to the end of your file.\n",
      "\n",
      "/home/valentin/anaconda3/envs/ada/lib/python3.6/site-packages/plotly/offline/offline.py:635: UserWarning:\n",
      "\n",
      "Your filename `vulg_over_time` didn't end with .html. Adding .html to the end of your file.\n",
      "\n",
      "/home/valentin/anaconda3/envs/ada/lib/python3.6/site-packages/plotly/offline/offline.py:635: UserWarning:\n",
      "\n",
      "Your filename `contrib_over_time` didn't end with .html. Adding .html to the end of your file.\n",
      "\n",
      "/home/valentin/anaconda3/envs/ada/lib/python3.6/site-packages/plotly/offline/offline.py:635: UserWarning:\n",
      "\n",
      "Your filename `sentiment_over_time` didn't end with .html. Adding .html to the end of your file.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'file:///home/valentin/Documents/EPFL/Master/Semestre1/ADA/Reddit-opinions-polarization/plots/sentiment_over_time.html'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotly.offline.plot(agree_line_fig, auto_open=False, filename='agree_over_time')\n",
    "plotly.offline.plot(pos_line_fig, auto_open=False, filename='pos_over_time')\n",
    "plotly.offline.plot(vulg_line_fig, auto_open=False, filename='vulg_over_time')\n",
    "plotly.offline.plot(contrib_line_fig, auto_open=False, filename='contrib_over_time')\n",
    "plotly.offline.plot(lines_fig, auto_open=False, filename='sentiment_over_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('images'):\n",
    "    os.mkdir('images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.write_image(cat_neg_fig, 'images/cat_net_fig.svg', width=960, height=576)\n",
    "pio.write_image(cat_vulg_fig, 'images/cat_vulg_fig.svg', width=960, height=576)\n",
    "#pio.write_image(scatter_fig, 'images/scatter_fig.svg', width=1800, height=900)\n",
    "#pio.write_image(scatter_fig, 'images/scatter_fig.svg', width=1200, height=800)\n",
    "#pio.write_image(scatter_fig, 'images/scatter_fig.svg', width=960, height=640)\n",
    "pio.write_image(scatter_fig, 'images/scatter_fig.svg', width=620, height=480)\n",
    "#pio.write_image(agree_line_fig, 'images/agree_line_fig.svg', width=1200, height=720)\n",
    "pio.write_image(agree_line_fig, 'images/agree_line_fig.svg', width=960, height=576)\n",
    "pio.write_image(pos_line_fig, 'images/pos_line_fig.svg', width=960, height=576)\n",
    "pio.write_image(vulg_line_fig, 'images/vulg_line_fig.svg', width=960, height=576)\n",
    "pio.write_image(contrib_line_fig, 'images/contrib_line_fig.svg', width=960, height=576)\n",
    "pio.write_image(lines_fig, 'images/lines_fig.svg', width=960, height=576)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What should we use as units for the different plots? Those are not really % as we did not scale them up to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
