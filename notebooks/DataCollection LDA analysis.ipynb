{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "%run insights.py\n",
    "%run plot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics during the 2016 election\n",
    "\n",
    "It is widely accepted and recognized in the political sphere that the U.S. 2016 presidential election greatly divided the U.S. citizens. As early as January 2016 [journalists were already reporting that the rethoric used by the various presidential candidates were unusually violent and agressive, resulting in a division among the opinions of the american people](https://www.washingtonpost.com/politics/a-divided-country-gets-a-divisive-election/2016/01/09/591bfccc-b61f-11e5-a842-0feb51d1d124_story.html?noredirect=on&utm_term=.54c240a270e9). A division which kept on growing through the year as the presidential candidates were striked by diverse controversies. \n",
    "\n",
    "Although Reddit discussions do not represent the voice of all american people, many subreddits served as a hub for internet users entitled in voicing their support for the candidate they wished would win. This provides us some natural aggregation of the opinions of people supporting each side of the election. [r/The_Donald]() and [r/hillaryclinton]() were the main subreddits for reddit users standing respectively for the Republican and the Democrat candidate. In order to observe the divisiveness, we chose to take a more specialized look to what were the most discussed topics in each community the week preceding the election day. However such communities suffer from echo chamber effect as highlighted before by the agreement factor from The_Donald being one of the highest among the bid subreddit. Thus we compare such topics with the ones discussed on r/news which will serve as a neutral ground of observation between the candidates respective communities. The agreement factor of the news subreddit being one of the lowest indicates the echo chamber effect has a lesser impact on this subreddit's threads. \n",
    "\n",
    "\n",
    "### Methodology: LDA\n",
    "\n",
    "Latent Dirichlet Allocation (LDA) was the unsupervised clustering method we chose in order to model Reddit discussions topics. Given a corpus of documents and a topic's number, LDA assumes that each document is the produce of a mixture of the given number of topic. We can thus infer the topic that might be the subject of the documents collection.\n",
    "\n",
    "In our case, we chose the documents to be directly the reddit comments, as it is the unit of a Reddit discussion. Some classic natural language preprocessing has to be done for LDA to work properly. Thus each comment was first tokenized, then cleaned of any english stop words and finally lemmatized. Through experiences, some more preprocessing had to be done in order to remove idiosyncracies of Reddit comments:\n",
    "\n",
    "* Considering only comments with a positive score above 10: TODO\n",
    "* Considering only comments with more than 50 characters : \n",
    "* Considering comments not made by bot : \n",
    "* Removing the URLS: user tend to\n",
    "\n",
    "LDA can then be applied on the collection of preprocessed Reddit comments. Among the number of topics and words per topic, LDA can take also two other hyper parameters: the document concentration (alpha), and the topic concentration (beta). \n",
    "\n",
    "The alpha parameter is proportional to how much topics constitues a document. In the context of Reddit comments, it is unlikely that a comment is about a lot of topics, as comments are rather short pieces of text and will generally focus on the subject of the thread. Thus a small value of alpha would be preferred.\n",
    "\n",
    "The beta parameters is inversely proportionnal to how much the topics are compromised of the same words. A low beta value would trigger LDA to produce topics which do not share many identical words.\n",
    "\n",
    "Experimentally, it was found that 8 topics of 5 words each with a 0.025 value for both beta and alpha produced the best topic modelling for our purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r/The_Donald"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r/hillaryclinton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r/news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
