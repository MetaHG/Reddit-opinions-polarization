{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Language processing\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Language processing with TextBlob\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = spark.read.load('../sample_parquet/first_1000/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare stopwords, stemmer and lemmatizer for messages preprocessing.\n",
    "en_stopwords = stopwords.words('english')\n",
    "en_stemmer = SnowballStemmer('english')\n",
    "en_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_messages = messages.filter(\"body != '[removed]' and body != '[deleted]'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_body(body, n_grams=1, left_pad_symbol=None, right_pad_symbol=None, lemmatizer=None, stemmer=None, \\\n",
    "                   stop_words=None, lemmatize_stop_words=False, stem_stop_words=False, remove_stop_words=False):\n",
    "    \"\"\"\n",
    "    Process the message bodies of the given rdd\n",
    "        \n",
    "    Parameters:\n",
    "        body: \n",
    "            string message body\n",
    "        n_gram: \n",
    "            size of the n_grams in the rdd output\n",
    "        lemmatizer: \n",
    "            lemmatizer to use on the message words. If None, words are not lemmatize\n",
    "        stemmer: \n",
    "            stemmer to use on the message words. If None, words are not stemmed.\n",
    "        stop_words: \n",
    "            list of words to consider as stop words\n",
    "        lemmatize_stop_words: \n",
    "            boolean to lemmatize stop words\n",
    "        stem_stop_words: \n",
    "            boolean to stem stop words\n",
    "        remove_stop_words: \n",
    "            boolean to remove stop words from the tokens\n",
    "        \n",
    "    Returns:\n",
    "        rdd of the form (parent_id, id, processed_msg_body)\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = nltk.word_tokenize(body)\n",
    "\n",
    "    if stop_words is not None:\n",
    "        if remove_stop_words:\n",
    "            tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    if lemmatizer is not None:\n",
    "        if remove_stop_words or stop_words is None:\n",
    "            tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "        elif not lemmatize_stop_words:\n",
    "                tokens = [lemmatizer.lemmatize(token) if token not in stop_words else token for token in tokens]\n",
    "\n",
    "    if stemmer is not None:\n",
    "        if remove_stop_words or stop_words is None:\n",
    "            tokens = [stemmer.stem(token) for token in tokens]\n",
    "        elif not stem_stop_words:\n",
    "                tokens = [stemmer.stem(token) if token not in stop_words else token for token in tokens]\n",
    "\n",
    "    if n_grams < 1:\n",
    "        raise ValueError(\"n_grams should be bigger than 1\")\n",
    "    else:\n",
    "        if left_pad_symbol is not None and right_pad_symbol is not None:\n",
    "            tokens = list(nltk.ngrams(tokens, n_grams, True, True, left_pad_symbol, right_pad_symbol))\n",
    "        elif left_pad_symbol is not None:\n",
    "            tokens = list(nltk.ngrams(tokens, n_grams, pad_left=True, left_pad_symbol=left_pad_symbol))\n",
    "        elif right_pad_symbol is not None:\n",
    "            tokens = list(nltk.ngrams(tokens, n_grams, pad_right=True, right_pad_symbol=right_pad_symbol))\n",
    "        else:\n",
    "            tokens = list(nltk.ngrams(tokens, n_grams))\n",
    "\n",
    "    return [list(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.process_body(body, n_grams=1, left_pad_symbol=None, right_pad_symbol=None, lemmatizer=None, stemmer=None, stop_words=None, lemmatize_stop_words=False, stem_stop_words=False, remove_stop_words=False)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_body_udf = func.udf(process_body, ArrayType(ArrayType(StringType(), False), False))\n",
    "spark.udf.register('process_body', process_body, ArrayType(ArrayType(StringType(), False), False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence polarity using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.compute_nltk_polarity(msg_body)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_nltk_polarity(msg_body):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    msg_body = sid.polarity_scores(msg_body)\n",
    "    return msg_body\n",
    "\n",
    "compute_nltk_polarity_udf = func.udf(compute_nltk_polarity, MapType(StringType(), FloatType(), False))\n",
    "spark.udf.register('compute_nltk_polarity', compute_nltk_polarity_udf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_bodies = cleaned_messages.selectExpr('id', \"compute_nltk_polarity(body) as scores\")\n",
    "sent_nltk_scores = sent_bodies.select('id', 'scores.neg', 'scores.neu', 'scores.pos')\n",
    "sent_nltk_scores = sent_nltk_scores.toDF('id', 'nltk_negativity', 'nltk_neutrality', 'nltk_positivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+---------------+---------------+\n",
      "|     id|nltk_negativity|nltk_neutrality|nltk_positivity|\n",
      "+-------+---------------+---------------+---------------+\n",
      "|c595rma|          0.065|          0.935|            0.0|\n",
      "|c595rqe|            0.0|            1.0|            0.0|\n",
      "|c595rwc|            0.0|            1.0|            0.0|\n",
      "|c595sdr|            0.0|          0.878|          0.122|\n",
      "|c595sop|            0.0|            1.0|            0.0|\n",
      "|c595sui|            0.0|           0.84|           0.16|\n",
      "|c595t5u|           0.36|          0.443|          0.197|\n",
      "|c595ti7|            0.0|            1.0|            0.0|\n",
      "|c595u4r|            0.0|            1.0|            0.0|\n",
      "|c595ule|          0.377|          0.623|            0.0|\n",
      "|c595up4|            0.0|          0.408|          0.592|\n",
      "|c595v6i|          0.456|          0.544|            0.0|\n",
      "|c595w8b|            0.0|            1.0|            0.0|\n",
      "|c595whq|            0.0|            1.0|            0.0|\n",
      "|c595xbt|          0.121|          0.786|          0.093|\n",
      "|c595yos|          0.147|           0.63|          0.223|\n",
      "|c595ypd|            0.0|          0.385|          0.615|\n",
      "|c595z4z|            0.0|            1.0|            0.0|\n",
      "|c595zjd|          0.111|          0.801|          0.088|\n",
      "|c595zrv|            0.0|          0.408|          0.592|\n",
      "+-------+---------------+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_nltk_scores.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence polarity using TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using simple sentence polarity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.compute_blob_polarity(msg_body)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_blob_polarity(msg_body):\n",
    "    sentiment = TextBlob(msg_body).sentiment\n",
    "    return {'polarity': sentiment.polarity, 'subjectivity': sentiment.subjectivity}\n",
    "\n",
    "compute_blob_polarity_udf = func.udf(compute_blob_polarity, MapType(StringType(), FloatType(), False))\n",
    "spark.udf.register('compute_blob_polarity', compute_blob_polarity_udf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_blob_bodies = cleaned_messages.selectExpr('id', \"compute_blob_polarity(body) as scores\")\n",
    "sent_blob_scores = sent_blob_bodies.select('id', 'scores.polarity', 'scores.subjectivity')\n",
    "sent_blob_scores = sent_blob_scores.toDF('id', 'text_blob_polarity', 'text_blob_subjectivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----------------------+\n",
      "|     id|text_blob_polarity|text_blob_subjectivity|\n",
      "+-------+------------------+----------------------+\n",
      "|c595rma|      -0.041666668|                 0.425|\n",
      "|c595rqe|               0.0|                   0.0|\n",
      "|c595rwc|        0.20454545|             0.6818182|\n",
      "|c595sdr|               0.5|                   0.5|\n",
      "|c595sop|               0.0|                   0.0|\n",
      "|c595sui|        0.06666667|                   0.3|\n",
      "|c595t5u|               1.0|                   1.0|\n",
      "|c595ti7|               0.0|                   0.0|\n",
      "|c595u4r|               0.0|                   0.5|\n",
      "|c595ule|       -0.15982144|            0.60892856|\n",
      "|c595up4|        0.43333334|             0.8333333|\n",
      "|c595v6i|       -0.41666666|             0.6666667|\n",
      "|c595w8b|               0.0|                   0.0|\n",
      "|c595whq|          -0.15625|               0.40625|\n",
      "|c595xbt|        -0.6041667|             0.7513889|\n",
      "|c595yos|               0.1|            0.23333333|\n",
      "|c595ypd|               0.4|                   0.5|\n",
      "|c595z4z|               0.0|                   0.0|\n",
      "|c595zjd|           0.03125|            0.46458334|\n",
      "|c595zrv|               0.7|                   0.6|\n",
      "+-------+------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_blob_scores.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using twitter trained positive/negative naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.compute_blob_class_polarity(msg_body)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_blob_class_polarity(msg_body):\n",
    "    pol_class = TextBlob(msg_body, analyzer=NaiveBayesAnalyzer()).sentiment\n",
    "    return {'classification': -1 if pol_class.classification == 'neg' else 1, 'p_pos': pol_class.p_pos, 'p_neg': pol_class.p_neg}\n",
    "\n",
    "compute_blob_class_polarity_udf = func.udf(compute_blob_class_polarity, MapType(StringType(), FloatType(), False))\n",
    "spark.udf.register('compute_blob_class_polarity', compute_blob_class_polarity_udf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_blob_class_bodies = cleaned_messages.selectExpr('id', \"compute_blob_class_polarity(body) as scores\")\n",
    "sent_blob_class_scores = sent_blob_class_bodies.select('id', 'scores.classification', 'scores.p_pos', 'scores.p_neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This does not finish, classifier takes too long\n",
    "# sent_blob_class_scores.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other metrics (Vulgarity, hate speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|     id|              tokens|\n",
      "+-------+--------------------+\n",
      "|c595rma|[[The], [fear], [...|\n",
      "|c595rqe|     [[Upvote], [!]]|\n",
      "|c595rwc|[[It], ['s], [rea...|\n",
      "|c595sdr|[[What], ['s], [h...|\n",
      "|c595sop|[[does], [it], [e...|\n",
      "|c595sui|[[Your], [user], ...|\n",
      "|c595t5u|[[nope], [:], [D]...|\n",
      "|c595ti7|[[Along], [with],...|\n",
      "|c595u4r|[[Those], [both],...|\n",
      "|c595ule|[[If], [you], [ar...|\n",
      "|c595up4|[[Because], [easy...|\n",
      "|c595v6i|[[Does], [no], [o...|\n",
      "|c595w8b|[[Has], [the], [t...|\n",
      "|c595whq|[[Just], [because...|\n",
      "|c595xbt|[[Also], [,], [do...|\n",
      "|c595yos|[[Meh], [,], [it]...|\n",
      "|c595ypd|[[You], [enjoy], ...|\n",
      "|c595z4z|[[[], [Finnish], ...|\n",
      "|c595zjd|[[&], [gt], [;], ...|\n",
      "|c595zrv|[[Good], [insight...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens = cleaned_messages.selectExpr('id', 'process_body(body) as tokens')\n",
    "tokens.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matches(msg_grams, ref_grams, ref_grams_intensity=None):\n",
    "    msg_grams_joined = [' '.join(msg_gram) for msg_gram in msg_grams]\n",
    "    msg_grams_counter = Counter(msg_grams_joined)\n",
    "    count = 0\n",
    "    intensity = 0\n",
    "    for i, ref_gram in enumerate(ref_grams):\n",
    "        count = count + msg_grams_counter[ref_gram]\n",
    "        if ref_grams_intensity is not None:\n",
    "            intensity = intensity + msg_grams_counter[ref_gram] * ref_grams_intensity[i]\n",
    "    \n",
    "    if ref_grams_intensity is None:\n",
    "        return count\n",
    "    else: \n",
    "        return {'count':count, 'intensity':intensity}\n",
    "    \n",
    "def df_count_matches(gram_list):\n",
    "    return func.udf(lambda c: count_matches(c, gram_list), IntegerType())\n",
    "\n",
    "def df_count_matches_intensity(gram_list, intensity_list):\n",
    "    return func.udf(lambda c: count_matches(c, gram_list, intensity_list), MapType(StringType(), FloatType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vulgarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+\n",
      "|      en_bad_words|gram_rank|\n",
      "+------------------+---------+\n",
      "|              2g1c|        1|\n",
      "|     2 girls 1 cup|        4|\n",
      "|    acrotomophilia|        1|\n",
      "|alabama hot pocket|        3|\n",
      "|  alaskan pipeline|        2|\n",
      "|              anal|        1|\n",
      "|         anilingus|        1|\n",
      "|              anus|        1|\n",
      "|           apeshit|        1|\n",
      "|          arsehole|        1|\n",
      "|               ass|        1|\n",
      "|           asshole|        1|\n",
      "|          assmunch|        1|\n",
      "|       auto erotic|        2|\n",
      "|        autoerotic|        1|\n",
      "|          babeland|        1|\n",
      "|       baby batter|        2|\n",
      "|        baby juice|        2|\n",
      "|          ball gag|        2|\n",
      "|        ball gravy|        2|\n",
      "+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_words = spark.read.csv('../bad_words_lexicon/en.csv', header=True)\n",
    "bw_gram_rank = bad_words.withColumn('gram_rank', func.udf(lambda gram: len(gram.split()), IntegerType())(func.col('en_bad_words')))\n",
    "bw_gram_rank.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2g1c', 'acrotomophilia', 'anal', 'anilingus', 'anus']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw_1_grams = [i.en_bad_words for i in bw_gram_rank.filter('gram_rank == 1').select('en_bad_words').collect()]\n",
    "bw_1_grams[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|     id|nb_bw_matches|\n",
      "+-------+-------------+\n",
      "|c595rma|            0|\n",
      "|c595rqe|            0|\n",
      "|c595rwc|            0|\n",
      "|c595sdr|            0|\n",
      "|c595sop|            0|\n",
      "|c595sui|            0|\n",
      "|c595t5u|            0|\n",
      "|c595ti7|            0|\n",
      "|c595u4r|            0|\n",
      "|c595ule|            0|\n",
      "|c595up4|            0|\n",
      "|c595v6i|            0|\n",
      "|c595w8b|            0|\n",
      "|c595whq|            0|\n",
      "|c595xbt|            0|\n",
      "|c595yos|            0|\n",
      "|c595ypd|            0|\n",
      "|c595z4z|            0|\n",
      "|c595zjd|            0|\n",
      "|c595zrv|            0|\n",
      "+-------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bw_counter = tokens.withColumn(\"tokens\", df_count_matches(bw_1_grams)(func.col(\"tokens\"))).withColumnRenamed('tokens', 'nb_bw_matches')\n",
    "bw_counter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hate speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw hate words (basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+\n",
      "|  hate_words|gram_rank|\n",
      "+------------+---------+\n",
      "|        gypo|        1|\n",
      "|       gypos|        1|\n",
      "|        cunt|        1|\n",
      "|       cunts|        1|\n",
      "|  peckerwood|        1|\n",
      "| peckerwoods|        1|\n",
      "|     raghead|        1|\n",
      "|    ragheads|        1|\n",
      "|     cripple|        1|\n",
      "|    cripples|        1|\n",
      "|      niggur|        1|\n",
      "|     niggurs|        1|\n",
      "| yellow bone|        2|\n",
      "|yellow bones|        2|\n",
      "|      muzzie|        1|\n",
      "|     muzzies|        1|\n",
      "|      niggar|        1|\n",
      "|     niggars|        1|\n",
      "|      nigger|        1|\n",
      "|     niggers|        1|\n",
      "+------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hate_words = spark.read.csv('../hatespeech_lexicon/hatebase_dict.csv', header=True)\n",
    "hate_words = hate_words.withColumnRenamed(\"uncivilised',\", 'hate_words') \\\n",
    "                        .withColumn('hate_words', func.udf(lambda d: d[1:-2])(func.col('hate_words')))\n",
    "hw_gram_rank = hate_words.withColumn('gram_rank', func.udf(lambda gram: len(gram.split()), IntegerType())(func.col('hate_words')))\n",
    "hw_gram_rank.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gypo', 'gypos', 'cunt', 'cunts', 'peckerwood']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw_1_grams = [i.hate_words for i in hw_gram_rank.filter('gram_rank == 1').select('hate_words').collect()]\n",
    "hw_1_grams[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|     id|nb_hw_matches|\n",
      "+-------+-------------+\n",
      "|c595rma|            0|\n",
      "|c595rqe|            0|\n",
      "|c595rwc|            0|\n",
      "|c595sdr|            0|\n",
      "|c595sop|            0|\n",
      "|c595sui|            0|\n",
      "|c595t5u|            0|\n",
      "|c595ti7|            0|\n",
      "|c595u4r|            0|\n",
      "|c595ule|            1|\n",
      "|c595up4|            0|\n",
      "|c595v6i|            0|\n",
      "|c595w8b|            0|\n",
      "|c595whq|            0|\n",
      "|c595xbt|            0|\n",
      "|c595yos|            0|\n",
      "|c595ypd|            0|\n",
      "|c595z4z|            0|\n",
      "|c595zjd|            0|\n",
      "|c595zrv|            0|\n",
      "+-------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hw_counter = tokens.withColumn(\"tokens\", df_count_matches(hw_1_grams)(func.col(\"tokens\"))).withColumnRenamed('tokens', 'nb_hw_matches')\n",
    "hw_counter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refined hate words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+---------+\n",
      "|hate_words_ref|intensity|gram_rank|\n",
      "+--------------+---------+---------+\n",
      "|   allah akbar|     0.87|        2|\n",
      "|        blacks|    0.583|        1|\n",
      "|         chink|    0.467|        1|\n",
      "|        chinks|    0.542|        1|\n",
      "|         dykes|    0.602|        1|\n",
      "|        faggot|    0.489|        1|\n",
      "|       faggots|    0.675|        1|\n",
      "|          fags|    0.543|        1|\n",
      "|          homo|    0.667|        1|\n",
      "|        inbred|    0.583|        1|\n",
      "|        nigger|    0.584|        1|\n",
      "|       niggers|    0.672|        1|\n",
      "|        queers|      0.5|        1|\n",
      "|         raped|    0.717|        1|\n",
      "|       savages|    0.778|        1|\n",
      "|         slave|    0.667|        1|\n",
      "|          spic|     0.75|        1|\n",
      "|       wetback|    0.667|        1|\n",
      "|      wetbacks|    0.688|        1|\n",
      "|        whites|    0.556|        1|\n",
      "+--------------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hw_ref_schema = StructType([StructField('hate_words_ref', StringType(), False), StructField('intensity', FloatType(), False)])\n",
    "hate_words_ref = spark.read.csv('../hatespeech_lexicon/refined_ngram_dict.csv', header=True, schema=hw_ref_schema)\n",
    "hw_ref_gram_rank = hate_words_ref.withColumn('gram_rank', func.udf(lambda gram: len(gram.split()), IntegerType())(func.col('hate_words_ref')))\n",
    "hw_ref_gram_rank.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['blacks', 'chink', 'chinks', 'dykes', 'faggot'],\n",
       " [0.5830000042915344,\n",
       "  0.46700000762939453,\n",
       "  0.5419999957084656,\n",
       "  0.6019999980926514,\n",
       "  0.48899999260902405])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw_ref_1_grams = [i.hate_words_ref for i in hw_ref_gram_rank.filter('gram_rank == 1').select('hate_words_ref').collect()]\n",
    "hw_ref_1_intensity = [i.intensity for i in hw_ref_gram_rank.filter('gram_rank == 1').select('intensity').collect()]\n",
    "hw_ref_1_grams[0:5], hw_ref_1_intensity[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+\n",
      "|     id|intensity|count|\n",
      "+-------+---------+-----+\n",
      "|c595rma|      0.0| null|\n",
      "|c595rqe|      0.0| null|\n",
      "|c595rwc|      0.0| null|\n",
      "|c595sdr|      0.0| null|\n",
      "|c595sop|      0.0| null|\n",
      "|c595sui|      0.0| null|\n",
      "|c595t5u|      0.0| null|\n",
      "|c595ti7|      0.0| null|\n",
      "|c595u4r|      0.0| null|\n",
      "|c595ule|      0.0| null|\n",
      "|c595up4|      0.0| null|\n",
      "|c595v6i|      0.0| null|\n",
      "|c595w8b|      0.0| null|\n",
      "|c595whq|      0.0| null|\n",
      "|c595xbt|      0.0| null|\n",
      "|c595yos|      0.0| null|\n",
      "|c595ypd|      0.0| null|\n",
      "|c595z4z|      0.0| null|\n",
      "|c595zjd|      0.0| null|\n",
      "|c595zrv|      0.0| null|\n",
      "+-------+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hw_ref_counter = tokens.withColumn(\"tokens\", df_count_matches_intensity(hw_ref_1_grams, hw_ref_1_intensity)(func.col(\"tokens\"))).withColumnRenamed('tokens', 'nb_hw_ref_matches')\n",
    "hw_ref_scores = hw_ref_counter.select('id', 'nb_hw_ref_matches.intensity', 'nb_hw_ref_matches.count')\n",
    "hw_ref_scores.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
